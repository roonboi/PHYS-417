{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/roonboi/PHYS-417/blob/main/Project_Final.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "2c542647",
      "metadata": {
        "id": "2c542647"
      },
      "source": [
        "# Lab 8/9 Report:\n",
        "## Classify Gravitational Waves"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "87f0bdb8",
      "metadata": {
        "id": "87f0bdb8"
      },
      "source": [
        "### Name: Travis Hand, Arun Iyer"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d050509d",
      "metadata": {
        "id": "d050509d"
      },
      "outputs": [],
      "source": [
        "%matplotlib inline\n",
        "\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch.distributions import Categorical\n",
        "import h5py\n",
        "import tqdm\n",
        "import scipy\n",
        "import torch.optim as optim\n",
        "import torch.nn.functional as F\n",
        "from torch.utils.data import Dataset\n",
        "from torch.utils.data import DataLoader, random_split\n",
        "from scipy.signal import butter, sosfiltfilt, welch\n",
        "from torch.cuda.amp import autocast, GradScaler\n",
        "from torch.optim.swa_utils import AveragedModel, SWALR, update_bn\n",
        "from torch.utils.data import WeightedRandomSampler"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "XzNQ9BCtOp2v",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XzNQ9BCtOp2v",
        "outputId": "348fd31a-be03-4b4d-d3da-77c0f6ac49a5"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "j85Ee-63hnqs",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "j85Ee-63hnqs",
        "outputId": "50e1eb4e-f0e4-426f-857c-b568b3bcbb9c"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'/content/drive/MyDrive'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 3
        }
      ],
      "source": [
        "import os  # Standard Python library import\n",
        "os.chdir('/content/drive/MyDrive/')  # Change current working directory to Google Drive path\n",
        "os.getcwd()  # Confirm the current working directory"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "1e903c12",
      "metadata": {
        "id": "1e903c12"
      },
      "outputs": [],
      "source": [
        "# PyTorch Dataset base class\n",
        "class GravitationalWaveDataset(Dataset):\n",
        "    def __init__(self, file_path, label_map, train=True, transform=None, band=(20, 500), fs=4096):\n",
        "        \"\"\"\n",
        "        Initializes the dataset by reading the HDF5 file and preparing data and labels.\n",
        "\n",
        "        Args:\n",
        "            file_path (str): Path to the HDF5 file.\n",
        "            label_map (dict): Maps string labels to integer indices.\n",
        "            train (bool): Whether the dataset is used for training (enables augmentation).\n",
        "            transform (callable): Optional transform to apply to each sample.\n",
        "            band (tuple): Bandpass filter range (in Hz).\n",
        "            fs (int): Sampling frequency of the signal.\n",
        "        \"\"\"\n",
        "        self.data = []\n",
        "        self.labels = []\n",
        "        self.train = train\n",
        "        self.transform = transform\n",
        "        self.label_map = label_map\n",
        "        self.band = band\n",
        "        self.fs = fs\n",
        "\n",
        "        # Load data from HDF5 file\n",
        "        with h5py.File(file_path, 'r') as f:\n",
        "            for label, idx in label_map.items():\n",
        "                dataset = f[label][:]  # e.g., shape (2048, 2, 4096)\n",
        "                self.data.append(dataset)\n",
        "                self.labels += [idx] * len(dataset)\n",
        "\n",
        "        # Concatenate data arrays along the sample axis: final shape (N, 2, 4096)\n",
        "        self.data = np.concatenate(self.data)\n",
        "        self.labels = np.array(self.labels)\n",
        "\n",
        "    def __len__(self):\n",
        "        \"\"\"\n",
        "        Returns total number of samples in the dataset.\n",
        "        \"\"\"\n",
        "        return len(self.data)\n",
        "\n",
        "    def bandpass_filter(self, signal):\n",
        "        \"\"\"\n",
        "        Applies a 4th-order bandpass Butterworth filter to the input signal.\n",
        "\n",
        "        Args:\n",
        "            signal (np.array): 1D time-series signal.\n",
        "\n",
        "        Returns:\n",
        "            Filtered signal.\n",
        "        \"\"\"\n",
        "        sos = butter(N=4, Wn=[self.band[0], self.band[1]], btype='band', fs=self.fs, output='sos')\n",
        "        return sosfiltfilt(sos, signal)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        \"\"\"\n",
        "        Retrieves and processes a single sample from the dataset.\n",
        "\n",
        "        Args:\n",
        "            idx (int): Index of the sample to retrieve.\n",
        "\n",
        "        Returns:\n",
        "            x (torch.Tensor): Preprocessed signal tensor (2, 4096).\n",
        "            y (torch.Tensor): Corresponding label tensor.\n",
        "        \"\"\"\n",
        "        x = self.data[idx]\n",
        "        y = self.labels[idx]\n",
        "\n",
        "        # Normalize and filter each channel independently (L1, H1)\n",
        "        for i in range(x.shape[0]):\n",
        "            x[i] = (x[i] - x[i].mean()) / (x[i].std() + 1e-8)  # Normalize to zero mean, unit variance\n",
        "            x[i] = self.bandpass_filter(x[i])  # Apply bandpass filter\n",
        "\n",
        "        # Randomly shift the signal in time by up to ±128 samples (data augmentation)\n",
        "        shift = np.random.randint(-128, 128)\n",
        "        x = np.roll(x, shift, axis=-1)\n",
        "\n",
        "        # If in training mode, apply additional augmentation\n",
        "        if self.train:\n",
        "            L = x.shape[-1]\n",
        "            w = int(0.10 * L)  # 10% of the signal length as mask width\n",
        "            s = torch.randint(0, L - w, (1,)).item()  # Random start index\n",
        "            x[:, s : s + w] = 0  # Zero out both channels in the mask region\n",
        "            x = x + 0.001 * torch.randn_like(x)  # Add slight Gaussian noise\n",
        "\n",
        "        # Apply optional transform (if provided)\n",
        "        if self.transform:\n",
        "            x = self.transform(x)\n",
        "\n",
        "        # Convert to PyTorch tensors\n",
        "        x = torch.tensor(x, dtype=torch.float32)\n",
        "        y = torch.tensor(y, dtype=torch.long)\n",
        "        return x, y\n",
        "\n",
        "\n",
        "# Mapping class names to integer indices\n",
        "label_map = {\n",
        "    'background': 0,\n",
        "    'binaryblackhole': 1,\n",
        "    'ccsn': 2,\n",
        "    'glitch': 3\n",
        "}\n",
        "\n",
        "# Instantiate dataset (with augmentation enabled by default)\n",
        "dataset = GravitationalWaveDataset('./GW2_Andy.h5', label_map, train=True)\n",
        "\n",
        "# Split into training, validation, and test sets (70/20/10 split)\n",
        "train_size = int(0.7 * len(dataset))\n",
        "val_size = int(0.2 * len(dataset))\n",
        "test_size = len(dataset) - (train_size + val_size)\n",
        "\n",
        "train_dataset, val_dataset, test_dataset = random_split(\n",
        "    dataset, [train_size, val_size, test_size])\n",
        "\n",
        "# Toggle data augmentation for each subset\n",
        "train_dataset.dataset.train = True\n",
        "val_dataset.dataset.train = False\n",
        "test_dataset.dataset.train = False\n",
        "\n",
        "# Number of parallel data-loading worker processes\n",
        "worker_count = 6\n",
        "\n",
        "# DataLoader for training (shuffled, augmented)\n",
        "train_loader = DataLoader(train_dataset, batch_size=64, shuffle=True,\n",
        "                          num_workers=worker_count, pin_memory=True)\n",
        "\n",
        "# DataLoaders for validation and test (no shuffle, no augmentation)\n",
        "val_loader = DataLoader(val_dataset, batch_size=64, shuffle=False,\n",
        "                        num_workers=worker_count, pin_memory=True)\n",
        "\n",
        "test_loader = DataLoader(test_dataset, batch_size=64, shuffle=False,\n",
        "                         num_workers=worker_count, pin_memory=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "1cfe7863",
      "metadata": {
        "id": "1cfe7863"
      },
      "source": [
        "## Define Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "Ko9Z4LMpzwgp",
      "metadata": {
        "id": "Ko9Z4LMpzwgp"
      },
      "outputs": [],
      "source": [
        "# 1D Inception block adapted for time-series signals\n",
        "class InceptionBlock1D(nn.Module):\n",
        "    def __init__(self, in_ch, out_ch, stride=1, depthwise=False):\n",
        "        super().__init__()\n",
        "\n",
        "        # Inner function to define convolution layer(s)\n",
        "        def conv(k):\n",
        "            # Use depthwise separable convolution if enabled\n",
        "            if depthwise:\n",
        "                return nn.Sequential(\n",
        "                    # Depthwise convolution: one filter per input channel\n",
        "                    nn.Conv1d(in_ch, in_ch, k, stride=stride,\n",
        "                              padding=k//2, groups=in_ch, bias=False),\n",
        "                    # Pointwise convolution: mixes channels\n",
        "                    nn.Conv1d(in_ch, out_ch, 1, bias=False))\n",
        "            else:\n",
        "                # Standard convolution\n",
        "                return nn.Conv1d(in_ch, out_ch, k,\n",
        "                                 stride=stride, padding=k//2, bias=False)\n",
        "\n",
        "        # Four convolution branches with different receptive fields\n",
        "        self.branch1 = conv(1)  # Smallest kernel: fine detail\n",
        "        self.branch3 = conv(3)  # Medium kernel: moderate context\n",
        "        self.branch5 = conv(5)  # Large kernel: broader features\n",
        "        self.branch7 = conv(7)  # Largest kernel: long-range dependencies\n",
        "\n",
        "        # Pooling branch: aggregates context, then reduces channels via 1x1 conv\n",
        "        self.pool     = nn.MaxPool1d(3, stride=stride, padding=1)\n",
        "        self.br_pool  = nn.Conv1d(in_ch, out_ch, 1, bias=False)\n",
        "\n",
        "    def forward(self, x):\n",
        "        # Concatenate the outputs from all five branches along the channel axis\n",
        "        return torch.cat([\n",
        "            self.branch1(x),\n",
        "            self.branch3(x),\n",
        "            self.branch5(x),\n",
        "            self.branch7(x),\n",
        "            self.br_pool(self.pool(x))\n",
        "        ], dim=1)\n",
        "\n",
        "\n",
        "# Main CNN model for gravitational wave classification\n",
        "class GWClassifier(nn.Module):\n",
        "    def __init__(self,\n",
        "                 in_channels: int = 2,         # Two detectors: L1, H1\n",
        "                 base_channels: int = 32,      # Base width for channels\n",
        "                 num_classes: int = 4,         # Number of output classes\n",
        "                 depthwise: bool = False):     # Whether to use depthwise separable convs\n",
        "        super().__init__()\n",
        "\n",
        "        self.branch_count = 5  # Each Inception block outputs 5 * out_channels\n",
        "\n",
        "        # -------------------- Block 1 --------------------\n",
        "        self.incept1 = InceptionBlock1D(\n",
        "            in_channels, base_channels,\n",
        "            stride=2, depthwise=depthwise)  # Downsamples by factor of 2\n",
        "        self.out1_channels = self.branch_count * base_channels\n",
        "        self.bn1 = nn.BatchNorm1d(self.out1_channels)\n",
        "\n",
        "        # -------------------- Block 2 --------------------\n",
        "        self.incept2 = InceptionBlock1D(\n",
        "            self.out1_channels, base_channels * 2,\n",
        "            stride=2, depthwise=depthwise)\n",
        "        self.out2_channels = self.branch_count * base_channels * 2\n",
        "        self.bn2 = nn.BatchNorm1d(self.out2_channels)\n",
        "\n",
        "        # -------------------- Block 3 --------------------\n",
        "        self.incept3 = InceptionBlock1D(\n",
        "            self.out2_channels, base_channels * 2,\n",
        "            stride=2, depthwise=depthwise)\n",
        "        self.out3_channels = self.branch_count * base_channels * 2\n",
        "        self.bn3 = nn.BatchNorm1d(self.out3_channels)\n",
        "\n",
        "        # -------------------- Block 4 --------------------\n",
        "        self.incept4 = InceptionBlock1D(\n",
        "            self.out3_channels, base_channels * 2,\n",
        "            stride=2, depthwise=depthwise)\n",
        "        self.out4_channels = self.branch_count * base_channels * 2\n",
        "        self.bn4 = nn.BatchNorm1d(self.out4_channels)\n",
        "\n",
        "        # -------------------- Classification Head --------------------\n",
        "\n",
        "        # Global pooling (per feature map) reduces time dimension to 1\n",
        "        self.global_pool_avg = nn.AdaptiveAvgPool1d(1)\n",
        "        self.global_pool_max = nn.AdaptiveMaxPool1d(1)\n",
        "\n",
        "        # Fully connected classifier\n",
        "        self.fc  = nn.Linear(self.out4_channels * 2, 32)  # Combined max + avg pooled channels\n",
        "        self.fc2 = nn.Linear(32, num_classes)\n",
        "\n",
        "        self.dropout = nn.Dropout(0.4)  # Prevent overfitting\n",
        "        self.relu = nn.ReLU(inplace=True)\n",
        "\n",
        "        self.init_weights()  # Optional custom initialization\n",
        "\n",
        "    # -------------------- Weight Initialization --------------------\n",
        "    def init_weights(self):\n",
        "        for m in self.modules():\n",
        "            if isinstance(m, nn.Conv1d):\n",
        "                nn.init.kaiming_normal_(m.weight, nonlinearity='relu')  # Good for ReLU\n",
        "                if m.bias is not None:\n",
        "                    nn.init.constant_(m.bias, 0)\n",
        "            elif isinstance(m, nn.BatchNorm1d):\n",
        "                nn.init.constant_(m.weight, 1)\n",
        "                nn.init.constant_(m.bias, 0)\n",
        "\n",
        "    # -------------------- Forward Pass --------------------\n",
        "    def forward(self, x):\n",
        "        # Pass through each inception block with BN and ReLU\n",
        "        x = self.relu(self.bn1(self.incept1(x)))\n",
        "        x = self.relu(self.bn2(self.incept2(x)))\n",
        "        x = self.dropout(x)  # Dropout between blocks\n",
        "        x = self.relu(self.bn3(self.incept3(x)))\n",
        "        x = self.relu(self.bn4(self.incept4(x)))\n",
        "\n",
        "        # Global average and max pooling: (B, C, T) → (B, C, 1)\n",
        "        avg_pool = self.global_pool_avg(x)\n",
        "        max_pool = self.global_pool_max(x)\n",
        "\n",
        "        # Concatenate pooled features and remove singleton time dim\n",
        "        x = torch.cat([avg_pool, max_pool], dim=1).squeeze(-1)  # (B, 2C)\n",
        "\n",
        "        x = self.dropout(x)\n",
        "        x = self.fc(x)\n",
        "        x = self.fc2(x)  # Final output logits (B, num_classes)\n",
        "\n",
        "        return x\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "O-pLW330N9Ow",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "O-pLW330N9Ow",
        "outputId": "3cf4e4ad-e8dd-4ed3-86b1-6e7650cf63de"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "cuda\n"
          ]
        }
      ],
      "source": [
        "# Use GPU if available, otherwise run on CPU\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "print(device)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "50cac3a5",
      "metadata": {
        "id": "50cac3a5"
      },
      "source": [
        "## Define Hyperparameters"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "bn8UAbhBUA4A",
      "metadata": {
        "id": "bn8UAbhBUA4A"
      },
      "outputs": [],
      "source": [
        "class FocalLoss(nn.Module):\n",
        "    def __init__(self, alpha=torch.ones(4), gamma=1.0, reduction=\"mean\"):\n",
        "        super().__init__()\n",
        "\n",
        "        # alpha: weighting factor for each class (e.g., to counter class imbalance)\n",
        "        self.alpha = alpha if alpha is not None else torch.ones(4)\n",
        "\n",
        "        # gamma: focusing parameter (higher → focus more on hard examples)\n",
        "        self.gamma = gamma\n",
        "\n",
        "        # reduction: \"mean\" to return average loss, else returns element-wise loss\n",
        "        self.reduction = reduction\n",
        "\n",
        "\n",
        "def forward(self, logits, targets):\n",
        "    # Step 1: Compute standard cross-entropy loss for each sample, without reducing to a mean\n",
        "    # Shape: (batch_size,)\n",
        "    ce = F.cross_entropy(logits, targets, reduction=\"none\")\n",
        "\n",
        "    # Step 2: Compute pt, the probability of the correct class for each sample\n",
        "    # Since ce = -log(pt), we get pt = exp(-ce)\n",
        "    pt = torch.exp(-ce)\n",
        "\n",
        "    # Step 3: Gather alpha for each sample based on its true class label\n",
        "    # alpha is a tensor of class weights (e.g., [1, 2, 1, 1] for class imbalance)\n",
        "    # Shape of at: (batch_size,)\n",
        "    at = self.alpha.to(logits.device).gather(0, targets)\n",
        "\n",
        "    # Step 4: Compute focal loss for each sample\n",
        "    # The formula is: FL = alpha_t * (1 - pt)^gamma * CE\n",
        "    # - (1 - pt)^gamma reduces the weight of easy examples\n",
        "    # - at scales the loss depending on class importance\n",
        "    focal = at * (1 - pt) ** self.gamma * ce\n",
        "\n",
        "    # Step 5: Return either the mean of losses or the raw loss per sample\n",
        "    return focal.mean() if self.reduction == \"mean\" else focal\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "9c001665",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9c001665",
        "outputId": "633ac42d-5420-4684-e70f-041190483261"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-8-3f13cac44cf7>:11: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.\n",
            "  scaler = GradScaler()\n"
          ]
        }
      ],
      "source": [
        "# Fix random seed\n",
        "torch.manual_seed(25)\n",
        "\n",
        "# Define Epochs\n",
        "num_epochs = 30\n",
        "\n",
        "# Define RNN network\n",
        "model = GWClassifier(base_channels=64, depthwise=True)\n",
        "\n",
        "# Define scaler\n",
        "scaler = GradScaler()\n",
        "\n",
        "# Define loss function and optimizer\n",
        "ce_weights = torch.tensor([1.45, 1.0, 1.25, 1.0],   # bg, bbh, ccsn, glitch\n",
        "                          dtype=torch.float32,\n",
        "                          device=device)\n",
        "criterion = nn.CrossEntropyLoss(weight=ce_weights, label_smoothing=0.05)\n",
        "optimizer = optim.Adam(model.parameters(), lr=1e-4, weight_decay=1e-4)\n",
        "\n",
        "# One-Cycle LR schedule\n",
        "steps_per_epoch = len(train_loader)\n",
        "scheduler = torch.optim.lr_scheduler.OneCycleLR(\n",
        "    optimizer,\n",
        "    max_lr=5e-3,\n",
        "    steps_per_epoch=steps_per_epoch,\n",
        "    epochs=num_epochs,\n",
        "    pct_start=0.3\n",
        ")\n",
        "\n",
        "# Best Bias for CCSN\n",
        "best_bias = -0.05\n",
        "\n",
        "swa_start = int(0.8 * num_epochs) # start averaging after 80 %\n",
        "swa_model  = AveragedModel(model).to(device) # running weight average\n",
        "swa_sched  = SWALR(optimizer, swa_lr=3e-4) # flat, low LR once SWA begins\n",
        "\n",
        "# add .cuda() for GPU acceleration\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "model = model.to(device)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "a0b88a3d",
      "metadata": {
        "id": "a0b88a3d"
      },
      "source": [
        "## Identify Tracked Values"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "1a9efa78",
      "metadata": {
        "id": "1a9efa78"
      },
      "outputs": [],
      "source": [
        "# Tracking training loss per each input/target sequence fwd/bwd pass\n",
        "training_loss = []\n",
        "validation_accuracy = []"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "1b3bc1df",
      "metadata": {
        "id": "1b3bc1df"
      },
      "source": []
    },
    {
      "cell_type": "markdown",
      "id": "4b818cf8",
      "metadata": {
        "id": "4b818cf8"
      },
      "source": [
        "## Train Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "On4ni-cLToXs",
      "metadata": {
        "id": "On4ni-cLToXs"
      },
      "outputs": [],
      "source": [
        "def mixup(x, y, alpha=0.1):\n",
        "    # Sample lambda from a Beta(alpha, alpha) distribution\n",
        "    # This controls the strength of interpolation between samples\n",
        "    lam = np.random.beta(alpha, alpha)\n",
        "\n",
        "    # Generate a random permutation of the batch indices\n",
        "    # Used to shuffle the batch and pair each sample with another\n",
        "    idx = torch.randperm(x.size(0), device=x.device)\n",
        "\n",
        "    # Perform the linear interpolation between original and shuffled samples\n",
        "    # For input:  x_mix = lam * x + (1 - lam) * x[idx]\n",
        "    # For labels: y_mix = lam * y + (1 - lam) * y[idx] (computed externally)\n",
        "    return lam * x + (1 - lam) * x[idx], lam, idx\n",
        "\n",
        "\n",
        "mixup_start = 10 # epoch to start MixUp (0-based counting)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "5a812d26",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5a812d26",
        "outputId": "6d56ab69-89cf-40b6-ac48-db7da0f9d0d9",
        "scrolled": false
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  0%|          | 0/30 [00:00<?, ?it/s]<ipython-input-11-53166493dbd6>:24: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with autocast():  # Automatic Mixed Precision for efficiency\n",
            "  3%|▎         | 1/30 [00:12<05:54, 12.23s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/30 - Train Loss: 0.0189 - Train Acc: 0.5096 - Val Loss: 1.0970 - Val Acc: 0.4988\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  7%|▋         | 2/30 [00:22<05:04, 10.89s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 2/30 - Train Loss: 0.0149 - Train Acc: 0.6322 - Val Loss: 1.0382 - Val Acc: 0.6136\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 10%|█         | 3/30 [00:32<04:44, 10.55s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 3/30 - Train Loss: 0.0146 - Train Acc: 0.6554 - Val Loss: 0.8049 - Val Acc: 0.7479\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 13%|█▎        | 4/30 [00:42<04:28, 10.34s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 4/30 - Train Loss: 0.0131 - Train Acc: 0.7061 - Val Loss: 0.8325 - Val Acc: 0.6502\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 17%|█▋        | 5/30 [00:52<04:15, 10.23s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 5/30 - Train Loss: 0.0125 - Train Acc: 0.7300 - Val Loss: 0.8616 - Val Acc: 0.6770\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 20%|██        | 6/30 [01:02<04:04, 10.17s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 6/30 - Train Loss: 0.0118 - Train Acc: 0.7480 - Val Loss: 0.7679 - Val Acc: 0.7656\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 23%|██▎       | 7/30 [01:12<03:53, 10.13s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 7/30 - Train Loss: 0.0110 - Train Acc: 0.7810 - Val Loss: 0.7308 - Val Acc: 0.7790\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 27%|██▋       | 8/30 [01:22<03:43, 10.17s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 8/30 - Train Loss: 0.0108 - Train Acc: 0.7900 - Val Loss: 0.7339 - Val Acc: 0.7747\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 30%|███       | 9/30 [01:32<03:34, 10.19s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 9/30 - Train Loss: 0.0103 - Train Acc: 0.8073 - Val Loss: 0.7443 - Val Acc: 0.7821\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 33%|███▎      | 10/30 [01:43<03:24, 10.22s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 10/30 - Train Loss: 0.0102 - Train Acc: 0.8057 - Val Loss: 0.6650 - Val Acc: 0.8303\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 37%|███▋      | 11/30 [01:53<03:14, 10.24s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 11/30 - Train Loss: 0.0119 - Train Acc: 0.7660 - Val Loss: 0.8720 - Val Acc: 0.6819\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 40%|████      | 12/30 [02:03<03:04, 10.23s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 12/30 - Train Loss: 0.0111 - Train Acc: 0.7924 - Val Loss: 0.9280 - Val Acc: 0.6532\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 43%|████▎     | 13/30 [02:14<02:54, 10.24s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 13/30 - Train Loss: 0.0117 - Train Acc: 0.7753 - Val Loss: 0.6910 - Val Acc: 0.7991\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 47%|████▋     | 14/30 [02:24<02:43, 10.25s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 14/30 - Train Loss: 0.0114 - Train Acc: 0.7815 - Val Loss: 0.6725 - Val Acc: 0.8248\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 50%|█████     | 15/30 [02:34<02:34, 10.27s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 15/30 - Train Loss: 0.0110 - Train Acc: 0.7954 - Val Loss: 0.5784 - Val Acc: 0.8547\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 53%|█████▎    | 16/30 [02:44<02:23, 10.27s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 16/30 - Train Loss: 0.0108 - Train Acc: 0.8035 - Val Loss: 0.6327 - Val Acc: 0.8352\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 57%|█████▋    | 17/30 [02:55<02:13, 10.30s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 17/30 - Train Loss: 0.0108 - Train Acc: 0.8037 - Val Loss: 0.6940 - Val Acc: 0.8034\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 60%|██████    | 18/30 [03:05<02:03, 10.28s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 18/30 - Train Loss: 0.0107 - Train Acc: 0.8064 - Val Loss: 0.7923 - Val Acc: 0.7015\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 63%|██████▎   | 19/30 [03:15<01:52, 10.27s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 19/30 - Train Loss: 0.0102 - Train Acc: 0.8197 - Val Loss: 0.5939 - Val Acc: 0.8516\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 67%|██████▋   | 20/30 [03:26<01:43, 10.33s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 20/30 - Train Loss: 0.0103 - Train Acc: 0.8187 - Val Loss: 0.5810 - Val Acc: 0.8565\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 70%|███████   | 21/30 [03:36<01:32, 10.29s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 21/30 - Train Loss: 0.0101 - Train Acc: 0.8246 - Val Loss: 0.6274 - Val Acc: 0.8107\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 73%|███████▎  | 22/30 [03:46<01:22, 10.33s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 22/30 - Train Loss: 0.0108 - Train Acc: 0.8043 - Val Loss: 0.5896 - Val Acc: 0.8614\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 77%|███████▋  | 23/30 [03:56<01:12, 10.29s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 23/30 - Train Loss: 0.0106 - Train Acc: 0.8101 - Val Loss: 0.6360 - Val Acc: 0.8242\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 80%|████████  | 24/30 [04:07<01:01, 10.23s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 24/30 - Train Loss: 0.0101 - Train Acc: 0.8227 - Val Loss: 0.5609 - Val Acc: 0.8681\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 83%|████████▎ | 25/30 [04:17<00:51, 10.23s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 25/30 - Train Loss: 0.0099 - Train Acc: 0.8320 - Val Loss: 0.6358 - Val Acc: 0.7943\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 87%|████████▋ | 26/30 [04:27<00:40, 10.24s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 26/30 - Train Loss: 0.0101 - Train Acc: 0.8235 - Val Loss: 0.5871 - Val Acc: 0.8394\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 90%|█████████ | 27/30 [04:37<00:30, 10.24s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 27/30 - Train Loss: 0.0102 - Train Acc: 0.8196 - Val Loss: 0.5525 - Val Acc: 0.8626\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 93%|█████████▎| 28/30 [04:48<00:20, 10.29s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 28/30 - Train Loss: 0.0101 - Train Acc: 0.8287 - Val Loss: 0.5778 - Val Acc: 0.8492\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 97%|█████████▋| 29/30 [04:58<00:10, 10.28s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 29/30 - Train Loss: 0.0101 - Train Acc: 0.8226 - Val Loss: 0.5732 - Val Acc: 0.8565\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 30/30 [05:08<00:00, 10.29s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 30/30 - Train Loss: 0.0098 - Train Acc: 0.8313 - Val Loss: 0.5723 - Val Acc: 0.8547\n",
            "SWA: updating BatchNorm statistics…\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ],
      "source": [
        "for epoch in tqdm.trange(num_epochs):  # Iterate through each training epoch\n",
        "    model.train()  # Set model to training mode\n",
        "\n",
        "    # Initialize running metrics\n",
        "    running_loss = 0.0\n",
        "    running_total = 0\n",
        "    correct = 0\n",
        "\n",
        "    # Loop through mini-batches\n",
        "    for batch_idx, (inputs, labels) in enumerate(train_loader):\n",
        "        inputs, labels = inputs.to(device), labels.to(device)\n",
        "\n",
        "        # ----------------------- MixUp Augmentation -----------------------\n",
        "        if epoch >= mixup_start:\n",
        "            inputs, lam, idx = mixup(inputs, labels)  # Mix input and shuffled versions\n",
        "            labels_a, labels_b = labels, labels[idx]  # Keep original and mixed labels\n",
        "        else:\n",
        "            lam = 1.0  # No mixing\n",
        "            labels_a, labels_b = labels, labels  # Dummy values\n",
        "\n",
        "        # ----------------------- Forward & Backward Pass -----------------------\n",
        "        optimizer.zero_grad(set_to_none=True)  # Clear gradients efficiently\n",
        "\n",
        "        with autocast():  # Automatic Mixed Precision for efficiency\n",
        "            outputs = model(inputs)\n",
        "\n",
        "            # Compute loss using MixUp interpolation if active\n",
        "            if lam == 1.0:\n",
        "                loss = criterion(outputs, labels_a)\n",
        "            else:\n",
        "                loss = lam * criterion(outputs, labels_a) + \\\n",
        "                       (1 - lam) * criterion(outputs, labels_b)\n",
        "\n",
        "        # Scale loss for mixed precision and backpropagate\n",
        "        scaler.scale(loss).backward()\n",
        "        scaler.step(optimizer)\n",
        "        scaler.update()\n",
        "\n",
        "        # ----------------------- Learning Rate Scheduler -----------------------\n",
        "        if epoch >= swa_start:\n",
        "            swa_sched.step()  # Small constant LR for SWA phase\n",
        "        else:\n",
        "            scheduler.step()  # Standard learning rate scheduler\n",
        "\n",
        "        # ----------------------- Accuracy Calculation -----------------------\n",
        "        _, preds = torch.max(outputs, 1)  # Get predicted class indices\n",
        "\n",
        "        if lam == 1.0:\n",
        "            batch_correct = (preds == labels_a).sum().item()\n",
        "        else:\n",
        "            # Compute soft MixUp accuracy as expected correct predictions\n",
        "            batch_correct = (\n",
        "                lam * (preds == labels_a).float() +\n",
        "                (1 - lam) * (preds == labels_b).float()\n",
        "            ).sum()\n",
        "\n",
        "        # Accumulate stats for epoch\n",
        "        running_loss += loss.detach()  # Don't track gradients for stats\n",
        "        correct += batch_correct\n",
        "        running_total += preds.size(0)  # Total number of samples seen\n",
        "\n",
        "    # ----------------------- End of Epoch Training Metrics -----------------------\n",
        "    train_loss = running_loss.cpu().item() / len(train_loader.dataset)\n",
        "    train_acc = correct / running_total\n",
        "    training_loss.append(train_loss)\n",
        "\n",
        "    # ----------------------- Validation Loop -----------------------\n",
        "    model.eval()  # Switch to eval mode for validation (disables dropout, etc.)\n",
        "    val_loss = 0.0\n",
        "    val_correct = 0\n",
        "\n",
        "    with torch.no_grad():  # No gradient tracking during validation\n",
        "        for inputs, labels in val_loader:\n",
        "            inputs, labels = inputs.to(device), labels.to(device)\n",
        "            outputs = model(inputs)\n",
        "            loss = criterion(outputs, labels)\n",
        "            val_loss += loss.item() * inputs.size(0)  # Accumulate total loss\n",
        "            _, preds = torch.max(outputs, 1)\n",
        "            val_correct += (preds == labels).sum().item()\n",
        "\n",
        "    val_loss /= len(val_loader.dataset)  # Normalize loss\n",
        "    val_acc = val_correct / len(val_loader.dataset)\n",
        "    validation_accuracy.append(val_acc)\n",
        "\n",
        "    # Print metrics for the epoch\n",
        "    print(f\"Epoch {epoch+1}/{num_epochs} - \"\n",
        "          f\"Train Loss: {train_loss:.4f} - Train Acc: {train_acc:.4f} - \"\n",
        "          f\"Val Loss: {val_loss:.4f} - Val Acc: {val_acc:.4f}\")\n",
        "\n",
        "    # ----------------------- SWA Weight Averaging -----------------------\n",
        "    if epoch >= swa_start:\n",
        "        swa_model.update_parameters(model)  # Update SWA weights with current model\n",
        "\n",
        "\n",
        "print(\"SWA: updating BatchNorm statistics…\")\n",
        "update_bn(train_loader, swa_model, device=device)  # Recompute batchnorm stats for SWA model\n",
        "model = swa_model  # Replace model with its SWA-averaged version for final use"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ZN2Sau9u0IyQ",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZN2Sau9u0IyQ",
        "outputId": "1db3a4f7-7712-46bf-fd29-2bf134d3c183"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-12-cb4aabc6fa74>:17: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.\n",
            "  scaler_ft = GradScaler()\n",
            "<ipython-input-12-cb4aabc6fa74>:35: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with autocast():\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[FT] Epoch 1/5 loss=0.0063  acc=0.8699\n",
            "[FT] Epoch 2/5 loss=0.0060  acc=0.8715\n",
            "[FT] Epoch 3/5 loss=0.0058  acc=0.8704\n",
            "[FT] Epoch 4/5 loss=0.0059  acc=0.8675\n",
            "[FT] Epoch 5/5 loss=0.0057  acc=0.8702\n",
            "Re-computing SWA weights & BatchNorm stats…\n"
          ]
        }
      ],
      "source": [
        "finetune_epochs = 5 # Number of epochs to fine-tune after main training\n",
        "\n",
        "# Define cross-entropy loss with class weights to handle class imbalance\n",
        "criterion_ft = nn.CrossEntropyLoss(weight=ce_weights)\n",
        "\n",
        "# Low learning rate optimizer for fine-tuning\n",
        "# AdamW is retained to preserve weight decay behavior\n",
        "optimizer_ft = torch.optim.AdamW(model.parameters(), lr=5e-5)\n",
        "\n",
        "# Cosine annealing learning rate scheduler over 5 epochs\n",
        "# Smoothly decreases LR from 5e-5 to 1e-6\n",
        "sched_ft = torch.optim.lr_scheduler.CosineAnnealingLR(\n",
        "    optimizer_ft, T_max=finetune_epochs, eta_min=1e-6\n",
        ")\n",
        "\n",
        "# Gradient scaler for mixed precision training (saves memory and speeds up training)\n",
        "scaler_ft = GradScaler()\n",
        "\n",
        "# Turn on training mode (enables dropout, batch norm updates, etc.)\n",
        "# MixUp is intentionally disabled here for training stability\n",
        "model.train()\n",
        "\n",
        "for ep in range(finetune_epochs):\n",
        "    # Reset tracking metrics for the epoch\n",
        "    running_loss, correct, total = 0.0, 0, 0\n",
        "\n",
        "    for inputs, labels in train_loader:\n",
        "        # Move inputs and labels to the selected device (e.g., GPU)\n",
        "        inputs, labels = inputs.to(device), labels.to(device)\n",
        "\n",
        "        # Reset gradients\n",
        "        optimizer_ft.zero_grad(set_to_none=True)\n",
        "\n",
        "        # Forward pass with mixed precision\n",
        "        with autocast():\n",
        "            outputs = model(inputs)               # Forward pass\n",
        "            loss = criterion_ft(outputs, labels)  # Standard cross-entropy loss\n",
        "\n",
        "        # Backward pass with gradient scaling\n",
        "        scaler_ft.scale(loss).backward()\n",
        "        scaler_ft.step(optimizer_ft)\n",
        "        scaler_ft.update()\n",
        "\n",
        "        # Compute predictions\n",
        "        _, preds = torch.max(outputs, 1)\n",
        "\n",
        "        # Accumulate metrics\n",
        "        running_loss += loss.detach()\n",
        "        correct += (preds == labels).sum().item()\n",
        "        total += labels.size(0)\n",
        "\n",
        "    # Step the learning rate scheduler after each epoch\n",
        "    sched_ft.step()\n",
        "\n",
        "    # Log fine-tuning metrics for this epoch\n",
        "    print(f\"[FT] Epoch {ep+1}/{finetune_epochs} \"\n",
        "          f\"loss={running_loss.item()/total:.4f}  \"\n",
        "          f\"acc={correct/total:.4f}\")\n",
        "\n",
        "print(\"Re-computing SWA weights & BatchNorm stats…\")\n",
        "\n",
        "# Initialize SWA model from the final fine-tuned model weights\n",
        "swa_model = AveragedModel(model)\n",
        "swa_model.to(device)\n",
        "\n",
        "# Recompute BatchNorm running statistics using the training set\n",
        "update_bn(train_loader, swa_model, device=device)\n",
        "\n",
        "# Swap in the SWA-averaged model as the final model for evaluation/inference\n",
        "model = swa_model"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "0442adb6",
      "metadata": {
        "id": "0442adb6"
      },
      "source": [
        "## Visualize & Evaluate Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "v5KIdqksxmMB",
      "metadata": {
        "id": "v5KIdqksxmMB"
      },
      "outputs": [],
      "source": [
        "def tta_logits(xb):\n",
        "    # xb : (B, 2, 4096)\n",
        "    shifts  = [0, 64, 128, -64]\n",
        "    logits  = 0\n",
        "    for s in shifts:\n",
        "        rolled = torch.roll(xb, s, dims=-1)\n",
        "        logits += model(rolled)                 # normal\n",
        "        logits += model(torch.flip(rolled, [-1]))  # time-reversed\n",
        "    return logits / (2 * len(shifts))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "93cfc511",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "93cfc511",
        "outputId": "a8c47cdf-ab00-403b-c59c-cfdb33422d72"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "test_loss: 0.2806 -- test accuracy: 0.8659\n"
          ]
        }
      ],
      "source": [
        "# Set model to evaluation mode (disables dropout, uses running batchnorm stats)\n",
        "model.eval()\n",
        "\n",
        "# Initialize accumulators for test loss and accuracy\n",
        "test_loss = 0.0\n",
        "test_correct = 0\n",
        "\n",
        "# Disable gradient computation to speed up inference and reduce memory usage\n",
        "with torch.no_grad():\n",
        "    for inputs, labels in test_loader:\n",
        "        # Move input tensors to the appropriate device (CPU or GPU)\n",
        "        inputs, labels = inputs.to(device), labels.to(device)\n",
        "\n",
        "        # Forward pass through the model (with optional Test-Time Augmentation)\n",
        "        outputs = tta_logits(inputs)  # Use TTA wrapper if defined (otherwise use model(inputs))\n",
        "\n",
        "        # Add a bias vector to logits for class calibration\n",
        "        # Only the third class (index 2) is adjusted by best_bias\n",
        "        bias = torch.tensor([0.0, 0.0, best_bias, 0.0], device=outputs.device)\n",
        "        outputs += bias\n",
        "\n",
        "        # Compute loss for the batch\n",
        "        loss = criterion(outputs, labels)\n",
        "\n",
        "        # Accumulate total loss (scaled by batch size)\n",
        "        test_loss += loss.item() * inputs.size(0)\n",
        "\n",
        "        # Get predicted class indices from logits\n",
        "        _, preds = torch.max(outputs, 1)\n",
        "\n",
        "        # Count number of correct predictions\n",
        "        test_correct += (preds == labels).sum().item()\n",
        "\n",
        "# Normalize total loss over entire validation set\n",
        "test_loss /= len(val_loader.dataset)\n",
        "\n",
        "# Compute overall accuracy over the test set\n",
        "test_acc = test_correct / len(test_loader.dataset)\n",
        "\n",
        "# Print final evaluation metrics\n",
        "print(f\"test_loss: {test_loss:.4f} -- test accuracy: {test_acc:.4f}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "PoF2Bmtu_qT7",
      "metadata": {
        "id": "PoF2Bmtu_qT7"
      },
      "outputs": [],
      "source": [
        "# Import seaborn for prettier plot\n",
        "import seaborn as sns  # Standard Python library import\n",
        "\n",
        "sns.set(style = 'whitegrid', font_scale = 2.5)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f2fc815b",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 390
        },
        "id": "f2fc815b",
        "outputId": "852d4fc9-d36e-4c76-8f26-a5104fefd2f2"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 599x429 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ],
      "source": [
        "# Plot the training loss and rolling mean training loss with respect to iterations\n",
        "# Feel free to change the window size\n",
        "plt.figure(figsize = (5.99, 4.29))\n",
        "\n",
        "plt.plot(training_loss, linewidth = 3)\n",
        "\n",
        "# Set tick label font sizes\n",
        "plt.xticks(fontsize=8)\n",
        "plt.yticks(fontsize=8)\n",
        "\n",
        "sns.despine()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "3OOXO86FTScG",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 349
        },
        "id": "3OOXO86FTScG",
        "outputId": "0a154b55-7b2e-4c73-bc54-ace4892ce6cc"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 650x362 with 2 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ],
      "source": [
        "from sklearn.metrics import confusion_matrix\n",
        "import seaborn as sns, matplotlib.pyplot as plt  # Import Matplotlib for plotting\n",
        "\n",
        "def biased_preds(xb, bias):\n",
        "    logits = tta_logits(xb)                     # 8-view TTA\n",
        "    logits[:, 2] += bias                        # index 2 = CCSN\n",
        "    return logits.argmax(1)\n",
        "\n",
        "model.eval()\n",
        "all_p, all_t = [], []\n",
        "with torch.no_grad():\n",
        "    for xb, yb in test_loader:\n",
        "        xb, yb = xb.to(device), yb.to(device)\n",
        "        all_p.append(biased_preds(xb, best_bias).cpu()) #  Run biased prediction, move to CPU\n",
        "        all_t.append(yb.cpu()) # Store true labels (also on CPU for sklearn)\n",
        "\n",
        "cm = confusion_matrix(torch.cat(all_t), torch.cat(all_p))\n",
        "\n",
        "fig, ax = plt.subplots(figsize=(6.5, 3.62))\n",
        "\n",
        "sns.heatmap(\n",
        "    cm,\n",
        "    annot=True,\n",
        "    cmap='Blues',\n",
        "    fmt='d',\n",
        "    vmin=0,                       # force the scale to start at 0\n",
        "    xticklabels=list(label_map.keys()),\n",
        "    yticklabels=list(label_map.keys()),\n",
        "    annot_kws={\"size\": 8},        # numbers in the cells\n",
        "    ax=ax,\n",
        "    cbar_kws={\n",
        "        \"label\": \"Count\",         # add the label here\n",
        "        \"shrink\": 0.6,            # overall bar length (0-1)\n",
        "        \"aspect\": 25,             # bar thickness (higher -> thinner)\n",
        "        \"pad\": 0.02,              # gap between map & bar\n",
        "    }\n",
        ")\n",
        "ax.set_xticklabels(\n",
        "    ax.get_xticklabels(),\n",
        "    rotation=30,                  # a bit steeper so they clear the bar\n",
        "    ha='right',\n",
        "    rotation_mode='anchor',\n",
        "    fontsize=8\n",
        ")\n",
        "ax.set_yticklabels(ax.get_yticklabels(), fontsize=8)\n",
        "cbar = ax.collections[0].colorbar\n",
        "cbar.ax.tick_params(labelsize=8)               # ticks\n",
        "cbar.set_label(\"Count\", fontsize=8, rotation=270, labelpad=12)\n",
        "fig.tight_layout(pad=0.6)\n",
        "plt.show()"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "L4",
      "machine_shape": "hm",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.2"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}